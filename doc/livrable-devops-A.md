# Rapport DevOps

## Sommaire

##### I - Outils utilis√©s
##### II - D√©roulement de la pipeline de CI/CD
##### III - Plan de Reprise d‚ÄôActivit√©
##### IV - Credentials


## I - Outils utilis√©s
### 1. Outils d‚Äôint√©gration continue (CI)
        
L'int√©gration continue (CI) est une pratique de d√©veloppement logiciel qui consiste √† int√©grer r√©guli√®rement, et de mani√®re automatis√©e, les changements apport√©s par les d√©veloppeurs dans un projet. L'objectif principal est de d√©tecter rapidement les √©ventuelles erreurs et les conflits de code entre les diff√©rents modules du logiciel. Pour ce faire, des tests automatis√©s sont ex√©cut√©s √† chaque nouvelle int√©gration.
        
Nous utilisons l‚Äôoutil suivant pour l‚Äôint√©gration continue :
        
- **Jenkins**
            
Jenkins est un outil open-source d‚Äôautomatisation de build, de test et de d√©ploiement qui permet d'optimiser les projets en automatisant les t√¢ches r√©p√©titives, en favorisant l'int√©gration et le d√©ploiement continus, en permettant la personnalisation et en am√©liorant la qualit√© globale du processus de d√©veloppement et de d√©ploiement.
            
La pipeline est d√©clench√©e automatiquement √† chaque commit. Gr√¢ce √† Jenkins, nous pouvons surveiller et suivre l'√©tat de notre pipeline de CI/CD en temps r√©el, ce qui nous permet de d√©tecter rapidement les √©ventuelles erreurs, et √©viter de les mettre en production (via les pull requests).
            
### 2. Outils de d√©ploiement continue (CD)
        
Le d√©ploiement continu est une pratique de d√©veloppement logiciel qui vise √† automatiser le processus de mise en production des changements apport√©s √† un projet.
        
Nous utilisons les outils suivants pour le d√©ploiement continue :
        
- **Artifactory**
            
Artifactory est un syst√®me de d√©p√¥t de fichiers versionn√©s o√π l‚Äôon va pouvoir stocker nos artifacts. Il va permettre d'optimiser le temps de d√©ploiement sur Jenkins en stockant les artefacts dans un r√©f√©rentiel centralis√© et en permettant une gestion efficace des versions des artefacts. 
            
- **Docker Hub**
            
Docker Hub est un registre public d'images de conteneurs Docker, qui permet aux d√©veloppeurs de stocker, partager et distribuer des conteneurs Docker. Nous utilisons Docker Hub notamment pour la facilit√© de partage des images entre les developpeurs. 
            
## II - D√©roulement de la pipeline de CI/CD
    
Notre pipeline de CI/CD est g√©r√©e par Jenkins. La partie CI est d√©clench√©e automatiquement sur toutes les branches de notre projet √† chaque modification de code. Cette partie utilise les outils Maven et NPM pour construire et tester notre code. En utilisant cette m√©thode, nous pouvons v√©rifier rapidement et efficacement nos modifications pour d√©tecter les erreurs et les bugs potentiels avant de les d√©ployer sur notre environnement de production, soit la branche ‚Äúmain‚Äù. Cela permet √©galement aux diff√©rents membres du groupe de d√©velopper en parall√®le sur diff√©rentes branches sans affecter l'int√©grit√© du code.
    
En ce qui concerne la partie CD, nous avons configur√© Jenkins pour d√©clencher cette partie seulement sur la branche ‚Äúmain‚Äù, qui repr√©sente notre environnement de production. Dans cette √©tape, nous avons automatis√© le processus de d√©ploiement de nos applications en poussant les fichiers jar et les packages NPM versionn√©s sur Artifactory. Nous utilisons ensuite ces artefacts pour construire des images Docker, qui sont ensuite tagg√©es et pouss√©es sur Docker Hub, afin d‚Äô√™tre disponibles sur Internet.  En utilisant cette m√©thode, nous avons r√©ussi √† am√©liorer consid√©rablement notre processus de d√©veloppement en acc√©l√©rant le d√©ploiement de notre projet et en r√©duisant les risques d'erreurs et de bugs. 
    
Pour d√©marrer notre application, il faudra seulement de lancer le fichier **docker-compose.yml** fourni dans notre projet. Il permettra de d√©marrer les conteneurs du serveur, de la cli, des services de banque et de parking, et enfin de la base de donn√©es. Nous avons utilis√© une image Docker PostgreSQL pr√©-existante pour lancer notre base de donn√©es en tant que conteneur. Cependant, nous voulions √©galement nous assurer que les donn√©es stock√©es dans notre base de donn√©es √©taient persistantes et ne seraient pas perdues en cas d'arr√™t ou de red√©marrage du conteneur. Pour cela, nous avons utilis√© un volume Docker pour stocker les donn√©es de la base de donn√©es.
    
![Pipeline](images/pipeline.png)
    
## III - Plan de Reprise d‚ÄôActivit√©
### 1. Points critiques et causes potentielles d‚Äôincidents
        
La partie suivante d√©crit les points critiques de la pipeline de d√©ploiement de notre projet, et propose des alternatives en cas d‚Äôindisponibilit√© de chaque composant de l‚Äôinfrastructure. Les diff√©rentes parties sont class√©s du point le moins critique, au plus critique.
        
- **Smee**
            
Smee est un service gratuit qui permet de transmettre des messages webhook √† un serveur local ou situ√© dans un r√©seau priv√©. Notre machine virtuelle √©tant dans le r√©seau priv√© de l‚Äôuniversit√©, elle est prot√©g√©e r√©seau priv√© virtuel (VPN), ce qui emp√™che les services tiers de communiquer directement avec notre serveur. Smee est utilis√© pour contourner cette restriction en √©tablissant une connexion sortante de notre r√©seau priv√© vers le serveur Smee h√©berg√© sur Internet. Les √©v√©nements webhook de GitHub sont envoy√©s √† Smee, qui les transmet ensuite √† notre application via la connexion sortante.
            
 **Alternative**
            
Si Smee.io est indisponible, il est possible de d√©ployer notre propre instance de Smee sur un serveur. Smee est open-source et peut √™tre ex√©cut√© localement ou d√©ploy√© sur un serveur cloud. Des instructions d√©taill√©es pour d√©ployer Smee sur GitHub : **[https://github.com/probot/smee#deploy-your-own-proxy](https://github.com/probot/smee#deploy-your-own-proxy).** Une autre alternative serait d'utiliser un autre service similaire √† Smee, tel que Ngrok ou localtunnel.
            
- **Docker Hub**
            
En cas d'indisponibilit√© de Docker Hub, il est important de prendre quelques mesures pour assurer la continuit√© de nos op√©rations de d√©ploiement et de gestion d'images Docker.
            
**Alternative**
            
            Artifactory peut √™tre utilis√© comme un registre Docker priv√© pour stocker des images Docker. Cependant, les images ne seront pas disponibles √† l‚Äôext√©rieur de la VM. Sinon, il est √©galement possible de ne pas fournir l‚Äôimage Docker directement, mais plut√¥t les artefacts pouss√©s sur Artifactory, ainsi que les Dockerfile. Il sera possible alors de construire soit-m√™me sa propre image Docker.
            
- **Artifactory**
            
Nous utilisons la version open source de JFrog Artifactory. 
            
**Alternative**
            
En cas de probl√®me, il existe plusieurs alternatives √† Artifactory pour la gestion des artefacts. Nous pouvons citer par exemple GitHub Releases pour les ex√©cutables .jar, et GitHub Packages pour les packages npm. Ce sont des alternatives tout de m√™me limit√©e, ne prenant pas en compte la gestion du versionning. Il existe d‚Äôautres solutions √† √©tudier, telles que Nexus Repository Manager, JFrog Bintray, Cloudsmith, etc.
            
- **Jenkins**
            
Jenkins est consid√©r√© comme un point critique car en cas de panne, les mises √† jour de code peuvent ne pas √™tre test√©es et d√©ploy√©es correctement, ce qui peut entra√Æner des erreurs. De plus, il est int√©gr√© avec des outils tiers (Artifactory, Docker Hub). En cons√©quence, une panne de Jenkins peut entra√Æner une interruption de l'ensemble de la cha√Æne d'outils de d√©veloppement.
            
**Alternative** 
            
En cas de panne de Jenkins, Il est possible d‚Äôeffectuer les diff√©rentes √©tapes localement (voir pipeline locale, partie Machine virtuelle), mais c‚Äôest un processus long qui peut laisser place √† l‚Äôerreur humaine. En cas d‚Äôindisponibilit√© prolong√©e, il est possible de se tourner vers d‚Äôautres solutions telles que GitHub Actions. Il s'agit d'un service d'automatisation propos√© par GitHub, qui permet d'automatiser les processus de build, de test et de d√©ploiement d'applications directement √† partir de votre d√©p√¥t GitHub. GitHub Actions est √©troitement int√©gr√© avec GitHub, ce qui facilite la configuration et la gestion des workflows d'automatisation. C‚Äôest une alternative beaucoup plus limit√©e que Jenkins, mais qui fonctionnerait tr√®s bien dans le cadre de notre projet.
            
- **Github**
            
Une indisponibilit√© de GitHub peut entra√Æner des retards dans les contributions et la coordination entre les membres de l'√©quipe. Il sera √©galement compliqu√© d‚Äôacc√©der aux derni√®res versions, versions pr√©c√©dentes du code ou √† l'historique des modifications. Si le code n‚Äôa pas √©t√© sauvegard√©, les seules versions disponibles seront celles sur les machines locales des contributeurs du projet. 
            
 **Alternative**          
            
Si une collaboration avec d'autres personnes est n√©cessaire et que GitHub est indisponible, il est possible de synchroniser le code via une autre plateforme de collaboration telle que GitLab ou Bitbucket, qui offrent des fonctionnalit√©s similaires √† GitHub. Sinon, il est √©galement possible de lancer un serveur GitHub sur la VM.

Par ailleurs, pour ne pas perdre le repositorie h√©berg√© sur GitHub, il faut penser √† mettre en place un syst√®me de sauvegarde pour vos d√©p√¥ts GitHub, en utilisant des outils tels que GitBackup ou GitMirror, qui permettent de cloner les d√©p√¥ts GitHub vers une autre plateforme de gestion de versions ou de stockage de code.
            
- **Machine virtuelle**
            
La machine virtuelle (VM) repr√©sente le point critique le plus important de ce projet.
            
Il est possible de partir d‚Äôune VM vierge, auquel cas il faut suivre la proc√©dure de r√©installation. Dans le cas o√π la VM a subit un red√©marrage mais que tous les fichiers sont encore pr√©sents, il faut simplement suivre la proc√©dure de red√©marrage.
            
Enfin, il est possible que la machine virtuelle soit compl√®tement indisponible. Dans ce cas, il est possible de passer par une pipeline locale, en clonant le projet sur sa machine depuis GitHub, √† l‚Äôissue de laquelle nous pourrons trouver les derni√®res versions des images sur Docker Hub (non impact√© par une indisponibilit√© de la VM).
            
**Alternative** Pipeline locale 
            
<u>Build & Test Maven + Docker Build</u>
            
Il faut cr√©er des scripts de build qui compile chaque module et construit les images Docker.
            
```bash
# backend/build.sh
#!/bin/bash
echo "Compiling the TCF Spring BACKEND within a multi-stage docker build"
mvn clean package
docker build --build-arg JAR_FILE=target/backend-<version>.jar -t devopsteama/backend .
            
# cli/build.sh
#!/bin/bash
echo "Compiling the TCF Spring CLI within a multi-stage docker build"
mvn clean package
docker build --build-arg JAR_FILE=target/cli-<version>.jar -t devopsteama/cli .
            
# bank/build.sh
#!/bin/bash
echo "Compiling the NestJS Bank"
npm install
docker build -t devopsteama/bank .
            
# iswypls/build.sh
#!/bin/bash
echo "Compiling the NestJS Parking service"
npm install
docker build -t devopsteama/iswypls .
```
            
Enfin, il faut un script √† la racine du projet : **build-all.sh**.
            
```bash
#!/bin/bash

function build_dir()  
{
    cd $1
    chmod u+x build.sh
    ./build.sh
    cd ..
}

echo "** Building all"

build_dir "cli"

build_dir "bank"

build_dir "iswypls"

build_dir "backend"

echo "** Done building all"
```
            
<u>Docker Tag & Push</u>
            
```bash
# TAG
docker tag devopsteama/backend:latest devopsteama/backend:${VERSION}
docker tag devopsteama/cli:latest devopsteama/cli:${VERSION}
docker tag devopsteama/iswypls:latest devopsteama/iswypls:${VERSION}
docker tag devopsteama/bank:latest devopsteama/bank:${VERSION}
# PUSH
docker push devopsteama/backend:${VERSION}
docker push devopsteama/cli:${VERSION}
docker push devopsteama/iswypls:${VERSION}
docker push devopsteama/bank:${VERSION}
```
            
Les derni√®res versions des images sont disponibles sur Docker Hub. Ce r√©sultat est le m√™me en passant par la pipeline locale ou en passant par la pipeline Jenkins. Nous pouvons donc d√©marrer les conteneurs en utilisant la commande suivante : `docker-compose up -d` (sans oublier de mettre √† jour les versions dans le docker-compose.yml).
            
### 2. Proc√©dure de r√©installation
        
**Temps n√©cessaire √† la remise en marche ~ 2 heures** 
        
Cette proc√©dure permet de recr√©er tout l‚Äôenvironnement et mettre en place tous les outils √† partir d‚Äôune VM vierge.
        
#### **Jenkins**
            
üí° **Tutoriel Jenkins :** [https://www.cloudbees.com/blog/how-to-install-and-run-jenkins-with-docker-compose](https://www.cloudbees.com/blog/how-to-install-and-run-jenkins-with-docker-compose)


            
**√âtape 1 -** Configurer le controller Jenkins.  Une fois sur la VM, lancer les commandes Jenkins :
            
```bash
# Donner les droits root pour plus de simplicit√©
sudo usermod -aG docker teama
# Cr√©er un dossier qui contient toute la configuration Jenkins
mkdir jenkins_compose
cd jenkins-compose
```
            
**√âtape 2 -** Cr√©er, √† partir de l‚Äôimage Jenkins, une nouvelle image qui contient les outils n√©cessaires au build, test et d√©ploiement du projet. Par exemple, nous avons install√© maven, npm, docker-compose, etc.
            
```docker
# DockerFile jenkins_new
FROM jenkins/ssh-agent:jdk17
USER root

RUN apt-get update -y && \
    apt-get upgrade -y && \
    apt-get install -y wget && \
    apt-get install -y git && \
    apt-get install -y maven && \
    apt-get install -y docker-compose && \
    apt-get install -y npm && \ 
    npm install -g @nestjs/cli && \
    wget -qO - https://releases.jfrog.io/artifactory/jfrog-gpg-public/jfrog_public_gpg.key | apt-key add && \
echo "deb https://releases.jfrog.io/artifactory/jfrog-debs xenial contrib" | tee -a /etc/apt/sources.list && apt update &&  apt install -y jfrog-cli-v2-jf && jf intro

USER jenkins
```
            
Enfin, builder l‚Äôimage Docker avec la commande suivante :
            
```bash
-docker build -t jenkins_new .
```
            
**√âtape 3 -** Cr√©er un docker-compose pour garantir la persistence des donn√©es. Il faut utiliser la nouvelle image jenkins g√©n√©r et √©galement choisir un port externe afin d‚Äôacc√©der √† l‚Äôinterface graphique (un port entre 8000 et 8030 qui n‚Äôest pas utilis√©, ces ports autoris√©s √† traverser le firewall. La deuxi√®me ligne du volume permet de cr√©er une socket docker qui donnera la possibilit√© √† Jenkins de cr√©er des conteneurs.
            
```yaml
# docker-compose.yaml
version: '3.8' # version du docker-compose √† utiliser
services: # d√©finition des services
  jenkins:
    image: jenkins/jenkins:lts
    privileged: true
    user: root
    ports:
      - 8000:8080
      - 50000:50000
    container_name: jenkins
    volumes:
      - /home/teama/jenkins_compose/jenkins_configuration:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
  agent:
    image: jenkins_new
    privileged: true
    user: root
    container_name: agent
    expose:
      - 22
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
```
            
**√âtape 4 -** D√©marrer le conteneur Jenkins et r√©cup√©rer les identifiants de connexion :
            
```bash
docker-compose up -d # start container
docker logs jenkins | less # retrieve password 
```
            
Se rendre sur l‚Äôinterface graphique > Entrer le password > **Install Suggested Plugins** > Cr√©er un user (admin/admin) > **Save and Continue** > **Save and Finish.**
            
**√âtape 5 -** Configurer l‚Äôagent Jenkins en SSH :
            
1. G√©n√©rer la cl√© SSH avec : `sh-keygen -t ed25519`
2. R√©cup√©rer la cl√© ssh priv√©e avec la commande : `cat **jenkins_agent**`
                
Dans Jenkins : **Manage Jenkins** > **Manage Credentials** > Click¬†**Jenkins**¬†under¬†**Stores scoped to Jenkins** > **Global credentials** > **********Add Credentials********** > Select **SSH Username with private key** > Limit the scope to System > Give the credential an ID > Provide a description > Enter¬†**jenkins** for a username > Under¬†**Private Key,**¬†check¬†**Enter directly** > Paste the the contents of¬†**jenkins_agent** file > ****OK.****
                
3. R√©cup√®rer la cl√© ssh publique avec la commande : `cat **jenkins_agent.pub**`
Modifier le docker-compose.yml afin d‚Äôajouter la cl√© publique en tant que variable d‚Äôenvironnement :
                
```yaml
# docker-compose.yaml
version: '3.8' # version du docker-compose √† utiliser
services: # d√©finition des services
  jenkins:
    image: jenkins/jenkins:lts
    privileged: true
    user: root
    ports:
      - 8000:8080
      - 50000:50000
    container_name: jenkins
    volumes:
      - /home/teama/jenkins_compose/jenkins_configuration:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
  agent:
    image: jenkins_new
    privileged: true
    user: root
    container_name: agent
    expose:
      - 22
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - JENKINS_AGENT_SSH_PUBKEY=${PUBLIC_KEY}
```
                
**√âtape 6 -** Stopper et red√©marrer les conteneurs.
                
```bash
docker-compose down # stop
docker-compose up -d # start
```
                
**√âtape 7 -** Configurer le wehbook sur [https://smee.io](https://smee.io). 
                
üí° **Tutoriel Smee :** [https://www.jenkins.io/blog/2019/01/07/webhook-firewalls/](https://www.jenkins.io/blog/2019/01/07/webhook-firewalls/)


                
Cliquer sur **Start a new channel** et r√©cup√©rer le lien webhook g√©n√©r√©. Ensuite, il faut cr√©er un second webhook sur le repository GitHub : **Settings > Webhooks > Add webhook >** Copier le lien g√©n√©r√© sur Smee dans la case **Payload URL** > Choisir **application/json** comme **Content Type** > Selectionner **Send me everything** > **Add webhook**.
                
Enfin, il faut lancer le client smee sur la VM. Nous utiliserons la commande screen afin de cr√©er un terminal persistent pour que le client tourne en continu.
                
```bash
 screen -AdmSL smee-client smee --url¬†${SMEE_URL}¬†--path /github-webhook/ --port ${PORT}
```
                
üö®¬†Le port du client doit √™tre identique au port sur lequel tourne Jenkins !
                
**√âtape 8 -** D√©finir l‚Äôagent Jenkins en tant que noeud.    
Aller sur l‚Äôinterface Jenkins : **Manage Jenkins > Manage Nodes and Clouds > New Node >** Lui donner un nom (ex: jenkins_agent) > Choisir 1 comme **Number of executors >** D√©finir le **Remote root directory** √† **/home/jenkins/agent >** S√©lectionner **Use this node as much as possible** sous **Usage** > D√©finir **agent** dans la case **Host*** > dans **Credentials**, choisir **jenkins** (cr√©√© √† l‚Äô√©tape 5) > Choisir **Non verifying Verification Strategy** sous **Host Key Verification Strategy >** Dans les param√®tres avanc√©es, donner le chemin vers Java sur la VM > **Enregistrer.**
                
‚úÖ¬†Il ne reste plus qu‚Äô√† configurer la pipeline Jenkins dans un fichier Jenkinsfile √† la racine du projet. Chaque commit d√©clenchera une pipeline accessible sur l‚Äôinterface graphique de Jenkins.
                
#### **Artifactory**
            
üí° **Tutoriel :** [https://jfrog.com/knowledge-base/artifactory-installation-quick-start-guide-docker-compose/](https://jfrog.com/knowledge-base/artifactory-installation-quick-start-guide-docker-compose/)
            
**√âtape 1 -** T√©l√©charger le package docker-compose sur la plateforme de t√©l√©chargement JFrog ([https://jfrog.com/download-legacy/?product=artifactory&installer=docker-compose](https://jfrog.com/download-legacy/?product=artifactory&installer=docker-compose)). Nous pouvons soit le faire directement sur la VM, soit le t√©l√©charger sur sa propre machine et le transf√©rer sur la VM √† l‚Äôaide de la commande suivante :
            
```bash
sudo scp -rp jfrog-artifactory-oss-<version>-compose.tar.gz [teama@vmpx01.polytech.unice.fr](mailto:teama@vmpx01.polytech.unice.fr):
```
            
**√âtape 2 -** Extraire les fichiers de l‚Äôarchive √† l‚Äôaide de la commande suivante :

```bash
tar -xzvf jfrog-artifactory-oss-<version>-compose.tar.gz
```
            
**√âtape 3 -** Se placer dans le dossier artifactory et lancer le script de configuration suivant : 
            
```bash
cd artifactory-oss-<version>
./config.sh
```
            
Il faut presser la touche Entr√©e pour r√©pondre aux deux premi√®res questions (afin de ne pas modifier les valeurs par d√©faut), r√©pondre **N** √† la question ‚ÄúAre you adding an additional node to an existing product cluster?‚Äù,  r√©pondre **N** √† la question ‚ÄúDo you want to install PostgreSQL?‚Äù et choisir la database **derby** √† la question suivante.
            
Une fois configur√©, il faut modifier le venv et de modifier la variable **JF_ROUTER_ENTRYPOINTS_EXTERNALPORT** qui repr√©sente le port externe de l‚Äôinterface graphique d‚ÄôArtifactory. Il faut choisir un port entre 8000 et 8030 qui n‚Äôest pas utilis√© (ports autoris√©s √† traverser le firewall) afin de pouvoir y acc√©der via le navigateur de notre machine.
            
**√âtape 4 -** D√©marrer le conteneur de l‚ÄôArtifactory en utilisant la commande suivante, et acc√©der √† l‚Äôinterface graphique afin de d√©finir un mot de passe :
            
```bash
docker-compose -p rt up -d # start
docker-compose -p rt down # stop
```
            
**√âtape 5 -** Configurer les repositories pour le d√©ploiement des modules Java. On a deux repositories √† configurer, celui des **snapshots** (instantan√©), et celui des **releases** (version stable)**.** Il faut suivre la m√™me procedure pour les deux.
            
Aller sur l‚Äôinterface graphique d‚ÄôArtifactory via l‚Äôadresse de la VM et le port configur√©. onglet **Application** > **Artifactory** > **Artifacts > Set Me Up >** Dans l‚Äôonglet **Configure**, cliquer sur **Generate Settings >** Copier les settings et coller le contenu dans un fichier dans le projet >. Modifier les param√®tres identifiant, mot de passe, et modifier l‚Äôid **central** par **jenkins.** Ce fichier sera utilis√© en tant que param√®tre de la commande **mvn deploy**. Ensuite, aller dans l‚Äôonglet **Deploy**, copier le code et coller le contenu dans les fichiers pom.xml des modules Java que l‚Äôon souhaite pousser sur Artifactory.
            
**√âtape 6 -** Pour d√©ployer les packages npm sur Artifactory, nous utilisons la cli Jfrog que nous avons pr√©alablement install√© sur l‚Äôagent Jenkins. Il suffit seulement de fournir l‚Äôartefact √† publier et le repositorie. 
            
```bash
jf rt upload ${PACKAGE} ${REPOSITORY_URL}
```
            
‚ö†Ô∏è**Troubleshooting :** il se peut qu‚Äôil y ait un probl√®me au moment de l‚Äôinitialisation des services d‚ÄôArtifactory. Dans ce cas, il faudra stopper le conteneur, supprimer le dossier **.jfrog** se trouvant dans le dossier **root**, et recommencer la proc√©dure d‚Äôinstallation.
            
        
Enfin, il faudra penser √† cr√©er un repository sur Docker Hub afin de pouvoir stocker les images g√©n√©r√©es par notre cha√Æne de d√©ploiement.
        
### 3. Proc√©dure de red√©marrage
        
**Temps n√©cessaire √† la remise en marche ~ 1 minute**
        
Les fichiers sont persistants mais pas les conteneurs. Comme nous avons realis√© toutes nos installations avec docker-compose, il tr√®s simple de relancer nos services en cas de red√©marrage de la VM. Il faut seulement red√©marrer les conteneurs de l‚ÄôArtifactory et de Jenkins.
        
```bash
# Red√©marrage de l'Artifactory
cd artifactory-oss-<version> && docker-compose -p rt up -d
# Red√©marrage de Jenkins
cd jenkins_compose && docker-compose up -d
```
        
## IV - Credentials
    
Dans cette partie, nous retrouvons tout les endpoints de nos services, ainsi que les credentials afin de pouvoir se connecter dessus.
    
> **VM**      
h√¥te:[vmpx01.polytech.unice.fr](http://vmpx01.polytech.unice.fr/)      
user: teama	      
pass: FhD2kCegNtqamuEV      
> 
    
> **Smee**      
webhook : [https://smee.io/KQQg8sraoDboNsa](https://smee.io/KQQg8sraoDboNsa)      
> 
    
> **Jenkins**      
endpoint: [vmpx01.polytech.unice.fr](http://vmpx01.polytech.unice.fr/):8000      
user: admin            
password: admin      
> 
    
> **Artifactory**      
endpoint: [vmpx01.polytech.unice.fr](http://vmpx01.polytech.unice.fr/):8002      
user: admin      
password: Admin06.      
> 
    
> **Docker Hub**      
endpoint: [https://hub.docker.com/repositories/devopsteama](https://hub.docker.com/repositories/devopsteama)      
user: devopsteama      
password: TeamAdmin06.      
>
